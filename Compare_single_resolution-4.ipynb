{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Resolution Modeling\n",
    "\n",
    "This tutorial shows how to model sources frome images observed with different telescopes. We will use a multiband observation with the Hyper-Sprime Cam (HSC) and a single high-resolution image from the Hubble Space Telescope (HST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "import astropy.io.fits as fits\n",
    "from astropy.wcs import WCS\n",
    "from scarlet.display import AsinhMapping\n",
    "from scarlet import Starlet\n",
    "from scarlet.wavelet import mad_wavelet\n",
    "import scipy.stats as scs\n",
    "from scarlet.initialization import build_initialization_coadd\n",
    "from COSMOS_Astrometry.astrometry_tools import HST_HSC_errors\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='gist_stern')\n",
    "matplotlib.rc('image', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Data\n",
    "\n",
    "We first load the HSC and HST images, swapping the byte order if necessary because a bug in astropy does not respect the local endianness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = ((150.2311511, 2.0725000),\n",
    "(150.23575, 2.0736144),\n",
    "(150.2407120, 2.06514),\n",
    "(150.2537000, 2.0480000),\n",
    "(150.3054000, 2.0823254),\n",
    "(150.3305180, 2.0707583))\n",
    "\n",
    "# Load HST psf\n",
    "psf_hst = fits.open('./data/PSF_HST.fits')[0].data\n",
    "psf_hst = psf_hst[None,:,:]\n",
    "psf_hst = scarlet.PSF(psf_hst)\n",
    "\n",
    "coord = coords[4]\n",
    "# Load HSC data\n",
    "obs_hdu = fits.open(f'data/hsc_ra={coord[0]:.5f}_dec={coord[1]:.5f}.fits')\n",
    "data_hsc = obs_hdu[0].data.byteswap().newbyteorder()\n",
    "wcs_hsc = WCS(obs_hdu[0].header)\n",
    "\n",
    "# Load HST data\n",
    "obs_hdu = fits.open(f'data/hst_ra={coord[0]:.5f}_dec={coord[1]:.5f}.fits')\n",
    "data_hst = obs_hdu[0].data.byteswap().newbyteorder()[None,:,:]\n",
    "wcs_hst = WCS(obs_hdu[0].header)\n",
    "\n",
    "# Load HSC psf\n",
    "psf_hsc = fits.open(f'data/psf_hsc_ra={coord[0]:.5f}_dec={coord[1]:.5f}.fits')[0].data\n",
    "psf_hsc = scarlet.PSF(psf_hsc)\n",
    "\n",
    "#HST_err, HSC_err = HST_HSC_errors(coord)\n",
    "#wcs_hst.wcs.crval -= HST_err\n",
    "#wcs_hsc.wcs.crval -= [0,*HSC_err]\n",
    "\n",
    "# Channels\n",
    "channels_hst = ['F814w']\n",
    "channels_hsc = ['g','r','i','z','y']\n",
    "\n",
    "# Scale the HST data\n",
    "_,n1,n2 = np.shape(data_hst)\n",
    "data_hst = data_hst.reshape(1, n1, n2).byteswap().newbyteorder()\n",
    "# Scale the HSC data\n",
    "r, N1, N2 = data_hsc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to create a source catalog for the images. We'll use `sep` for that, but any other detection method will do. Since HST is higher resolution and less affected by blending, we use it for detection but we also run detection on the HSC image to calculate the background RMS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sep\n",
    "\n",
    "class Data():\n",
    "    \n",
    "    def __init__(self, images, wcss, psfs, channels):\n",
    "        self.images = images\n",
    "        self.wcs = wcss\n",
    "        self.psfs = psfs.image\n",
    "        self.channels = channels\n",
    "\n",
    "def interpolate(data_lr, data_hr):\n",
    "    #Interpolate low resolution data to high resolution\n",
    "    coord_lr0 = (np.arange(data_lr.images.shape[1]), np.arange(data_lr.images.shape[1]))\n",
    "    coord_hr = (np.arange(data_hr.images.shape[1]), np.arange(data_hr.images.shape[1]))\n",
    "    coord_lr = scarlet.resampling.convert_coordinates(coord_lr0, data_lr.wcs, data_hr.wcs)\n",
    "    \n",
    "    interp = []\n",
    "    for image in data_lr.images:\n",
    "        interp.append(scarlet.interpolation.sinc_interp(image[None, :,:], coord_hr, coord_lr, angle=None)[0].T)\n",
    "    return np.array(interp)\n",
    "        \n",
    "def makeCatalog_multi(data_lr, data_hr, lvl = 3, wave = True):\n",
    "    #Create observations for each image\n",
    "    #Interpolate low resolution to high resolution\n",
    "    interp = interpolate(data_lr, data_hr)\n",
    "    #Normalisation of the interpolate low res images\n",
    "    interp = interp/np.sum(interp, axis = (1,2))[:,None, None]\n",
    "    #Normalisation of the high res data\n",
    "    hr_images = data_hr.images/np.sum(data_hr.images, axis = (1,2))[:,None, None]\n",
    "    #Detection image as the sum over all images\n",
    "    detect_image = np.sum(interp, axis = 0) + np.sum(hr_images, axis = 0)\n",
    "    detect_image *= np.sum(data_hr.images)\n",
    "    if np.size(detect_image.shape) == 3:\n",
    "        if wave:\n",
    "            #Wavelet detection in the first three levels\n",
    "            wave_detect = Starlet(detect_image.mean(axis=0), lvl = 4).coefficients\n",
    "            wave_detect[:,-1,:,:] = 0\n",
    "            detect = Starlet(coefficients = wave_detect).image\n",
    "        else:\n",
    "            #Direct detection\n",
    "            detect = detect_image.mean(axis=0)\n",
    "    else:\n",
    "        if wave:\n",
    "            wave_detect = Starlet(detect_image).coefficients\n",
    "            detect = wave_detect[0][0] + wave_detect[0][1] +  wave_detect[0][2] \n",
    "        else:\n",
    "            detect = detect_image\n",
    "    \n",
    "\n",
    "    bkg = sep.Background(detect)\n",
    "    catalog = sep.extract(detect, lvl, err=bkg.globalrms)\n",
    "    bg_rms = []\n",
    "    for data in datas:\n",
    "        bg_rms.append(mad_wavelet(data.images))\n",
    " \n",
    "    return catalog, bg_rms, detect_image\n",
    "\n",
    "def makeCatalog(data, lvl = 3, wave = True):\n",
    "    #Normalisation of the data\n",
    "    hr_images = data/np.sum(data, axis = (1,2))[:,None, None]\n",
    "    #Detection image as the sum over all images\n",
    "    detect_image = np.sum(hr_images, axis = 0)\n",
    "    \n",
    "    if np.size(detect_image.shape) == 3:\n",
    "        if wave:\n",
    "            #Wavelet detection in the first three levels\n",
    "            wave_detect = Starlet(detect_image.mean(axis=0), lvl = 4).coefficients\n",
    "            wave_detect[:,-1,:,:] = 0\n",
    "            detect = Starlet(coefficients = wave_detect).image\n",
    "        else:\n",
    "            #Direct detection\n",
    "            detect = detect_image.mean(axis=0)\n",
    "    else:\n",
    "        if wave:\n",
    "            wave_detect = Starlet(detect_image).coefficients\n",
    "            detect = wave_detect[0][0] + wave_detect[0][1] +  wave_detect[0][2] \n",
    "        else:\n",
    "            detect = detect_image\n",
    "    \n",
    "\n",
    "    bkg = sep.Background(detect)\n",
    "    catalog = sep.extract(detect, lvl, err=bkg.globalrms)\n",
    "    bg_rms = mad_wavelet(data)\n",
    "\n",
    "    return catalog, bg_rms, detect_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hr =  Data(data_hst, wcs_hst, psf_hst, channels_hst)\n",
    "data_lr =  Data(data_hsc, wcs_hsc, psf_hsc, channels_hsc)\n",
    "datas = [data_lr, data_hr]\n",
    "\n",
    "wave = 1\n",
    "lvl = 3\n",
    "catalog_multi, bg_rms_multi, detect_multi = makeCatalog_multi(data_lr, data_hr, lvl, wave)\n",
    "\n",
    "catalog_hsc, bg_rms_hsc, detect_hsc = makeCatalog(data_hsc, lvl, wave)\n",
    "catalog_hst, bg_rms_hst, detect_hst = makeCatalog(data_hst, lvl, wave)\n",
    "\n",
    "weights_hst = np.ones_like(data_hst) / (bg_rms_multi[1]**2)[:, None, None]\n",
    "weights_hsc = np.ones_like(data_hsc) / (bg_rms_multi[0]**2)[:, None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can visualize both the multiband HSC and single band HST images in their native resolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a color mapping for the HSC image\n",
    "hsc_norm = AsinhMapping(minimum=-1, stretch=2, Q=10)\n",
    "hst_norm = AsinhMapping(minimum=-1, stretch=10, Q=5)\n",
    "\n",
    "# Get the source coordinates from the HST catalog\n",
    "xt,yt = catalog_hst['x'], catalog_hst['y']\n",
    "xm,ym = catalog_multi['x'], catalog_multi['y']\n",
    "xc,yc = catalog_hsc['x'], catalog_hsc['y']\n",
    "# Convert the HST coordinates to the HSC WCS\n",
    "rat, dect = wcs_hst.wcs_pix2world(yt,xt,0)\n",
    "ram, decm = wcs_hst.wcs_pix2world(ym,xm,0)\n",
    "rac, decc, _ = wcs_hsc.wcs_pix2world(yc,xc,0, 0)\n",
    "\n",
    "Yt,Xt, l = wcs_hsc.wcs_world2pix(rat, dect, 0, 0)\n",
    "Ym,Xm, l = wcs_hsc.wcs_world2pix(ram, decm, 0, 0)\n",
    "Yc,Xc = wcs_hst.wcs_world2pix(rac, decc, 0)\n",
    "# Map the HSC image to RGB\n",
    "img_rgb = scarlet.display.img_to_rgb(data_hsc, norm=hsc_norm)\n",
    "# Apply Asinh to the HST data\n",
    "hst_img = scarlet.display.img_to_rgb(data_hst, norm=hst_norm)\n",
    "\n",
    "plt.figure(figsize=(15,30))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.plot(xc,yc, 's', label = 'HSC detection')\n",
    "plt.plot(Xt,Yt, 'og', label = 'HST detection')\n",
    "plt.plot(Xm,Ym, 'xr', label = 'Joint detection')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(hst_img)\n",
    "plt.axis('off')\n",
    "plt.plot(Xc,Yc, 's', label = 'HSC detection')\n",
    "plt.plot(xt,yt, 'og', label = 'HST detection')\n",
    "plt.plot(xm,ym, 'xr', label = 'Joint detection')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Frame and Observations\n",
    "\n",
    "Unlike the single resolution examples, we now have two different instruments with different pixel resolutions, so we need two different observations. Since the HST image is at a much higher resolution, we define our model `Frame` to use the HST PSF and the HST resolution. Because there is no resampling between the model frame and the HST observation, we can use the default `Observation` class for the HST data. The HSC images have lower resolution, so we need to resample the models to this frame, and that's done by `LowResObservation`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, it is possible to define a frame automatically from a set of observations. In this case, the user does not have to know which observation needs to be a `LowResObservation`. Instead, method `frome_observation` creates a frame that encapsluates, either the union or the intersection of a set of observations, and defines a frame based on the highest resolution available between all observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Automated frame definition\n",
    "# define two observation packages and match to frame\n",
    "multi_hst = scarlet.Observation(data_hst, wcs=wcs_hst, psfs=psf_hst, channels=channels_hst, weights=weights_hst)\n",
    "multi_hsc = scarlet.Observation(data_hsc, wcs=wcs_hsc, psfs=psf_hsc, channels=channels_hsc, weights=weights_hsc)\n",
    "\n",
    "print(type(multi_hst) is scarlet.Observation)\n",
    "# Keep the order of the observations consistent with the `channels` parameter\n",
    "# This implementation is a bit of a hack and will be refined in the future\n",
    "obs = [multi_hsc, multi_hst]\n",
    "frame = scarlet.Frame.from_observations(obs, coverage = 'intersection')\n",
    "multi_hsc, multi_hst = obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we are going to compare the fit to the data using HSC data alone, HST data alone and the multi-reolution framework applied to the combination of HST and HSC. We need to build a frame for each of these cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_hst = scarlet.Observation(data_hst, wcs=wcs_hst, psfs=psf_hst, channels=channels_hst, weights=weights_hst)\n",
    "obs_hsc = scarlet.Observation(data_hsc, wcs=wcs_hsc, psfs=psf_hsc, channels=channels_hsc, weights=weights_hsc)\n",
    "\n",
    "HSC_frame = scarlet.Frame(\n",
    "    data_hsc.shape,\n",
    "    wcs = wcs_hsc,\n",
    "    psfs=psf_hsc,\n",
    "    channels=channels_hsc)\n",
    "obs_hsc.match(HSC_frame)\n",
    "\n",
    "HST_frame = scarlet.Frame(\n",
    "    data_hst.shape,\n",
    "    wcs = wcs_hst,\n",
    "    psfs=psf_hst,\n",
    "    channels=channels_hst)\n",
    "obs_hst.match(HST_frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Sources and Blend\n",
    "\n",
    "We expect all sources to be galaxies, so we initialized them as `ExtendedSources`. Because the initialization takes a list of observations, we set the `obs_idx` argument to state which observation in the list of observations is used to initialize the morphology.\n",
    "\n",
    "`Blend` will hold a list of all sources and *all* observations to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Building a detection coadd\n",
    "coadd, bg_cutoff = build_initialization_coadd(obs, filtered_coadd=True)\n",
    "\n",
    "# Source initialisation\n",
    "sources = [\n",
    "    scarlet.ExtendedSource(frame, (ram[i], decm[i]), obs, \n",
    "                           symmetric=False, \n",
    "                           monotonic=True, \n",
    "                           coadd=coadd, \n",
    "                           bg_cutoff=bg_cutoff)\n",
    "    for i in range(ram.size)\n",
    "]\n",
    "blend_multi = scarlet.Blend(sources, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a detection coadd\n",
    "coadd, bg_cutoff = build_initialization_coadd(obs_hsc)\n",
    "\n",
    "# Source initialisation\n",
    "HSC_sources = [\n",
    "    scarlet.ExtendedSource(HSC_frame, (rac[i], decc[i]), obs_hsc, \n",
    "                           symmetric=False, \n",
    "                           monotonic=True, \n",
    "                           coadd=coadd, \n",
    "                           bg_cutoff=bg_cutoff)\n",
    "    for i in range(rac.size)\n",
    "]\n",
    "\n",
    "blend_hsc = scarlet.Blend(HSC_sources, obs_hsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a detection coadd\n",
    "coadd, bg_cutoff = build_initialization_coadd(obs_hst)\n",
    "\n",
    "# Source initialisation\n",
    "HST_sources = [\n",
    "    scarlet.ExtendedSource(HST_frame, (rat[i], dect[i]), obs_hst, \n",
    "                           symmetric=False, \n",
    "                           monotonic=True, \n",
    "                           coadd=coadd, \n",
    "                           bg_cutoff=bg_cutoff)\n",
    "    for i in range(rat.size)\n",
    "]\n",
    "\n",
    "blend_hst = scarlet.Blend(HST_sources, obs_hst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a detection coadd\n",
    "coadd, bg_cutoff = build_initialization_coadd(obs_hsc)\n",
    "\n",
    "# Source initialisation\n",
    "HSC_sources = [\n",
    "    scarlet.ExtendedSource(HSC_frame, (ram[i], decm[i]), obs_hsc, \n",
    "                           symmetric=False, \n",
    "                           monotonic=True, \n",
    "                           coadd=coadd, \n",
    "                           bg_cutoff=bg_cutoff)\n",
    "    for i in range(ram.size)\n",
    "]\n",
    "\n",
    "blend_multihsc = scarlet.Blend(HSC_sources, obs_hsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a detection coadd\n",
    "coadd, bg_cutoff = build_initialization_coadd(obs_hst)\n",
    "\n",
    "# Source initialisation\n",
    "HST_sources = [\n",
    "    scarlet.ExtendedSource(HST_frame, (ram[i], decm[i]), obs_hst, \n",
    "                           symmetric=False, \n",
    "                           monotonic=True, \n",
    "                           coadd=coadd, \n",
    "                           bg_cutoff=bg_cutoff)\n",
    "    for i in range(ram.size)\n",
    "]\n",
    "\n",
    "blend_multihst = scarlet.Blend(HST_sources, obs_hst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Initial guess\n",
    "\n",
    "Let's compare the initial guess of the model in both model frame and HSC observation frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_init(blend, obs, data, ids, img, title):\n",
    "    # Load the model and calculate the residual\n",
    "    model = blend.get_model()\n",
    "    model = obs.render(model)\n",
    "    \n",
    "    init_rgb = scarlet.display.img_to_rgb(model, norm=hsc_norm)\n",
    "    residual = data - model\n",
    "    \n",
    "    residual_rgb = scarlet.display.img_to_rgb(residual[:,:])\n",
    "    vmax = np.max(np.abs(residual_rgb))\n",
    "    if residual_rgb.shape[0]<2:\n",
    "        residual_rgb = residual_rgb[0,:,:]\n",
    "        print('zizi')\n",
    "    plt.figure(ids,figsize=(20, 8))\n",
    "    plt.suptitle(title, fontsize=36)\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Data\")\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(init_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Model\")\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(residual_rgb, vmin=-vmax, vmax=vmax, cmap = 'seismic')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Residuals\")\n",
    "    pass\n",
    "\n",
    "display_init(blend_hsc, obs_hsc, data_hsc, 0, img_rgb, 'HSC initialisation')\n",
    "display_init(blend_hst, obs_hst, data_hst, 1, data_hst[0], 'HST initialisation')\n",
    "display_init(blend_multihsc, obs_hsc, data_hsc, 2, img_rgb, 'HSC-multi initialisation')\n",
    "display_init(blend_multihst, obs_hst, data_hst, 3, data_hst[0], 'HST-multi initialisation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the model and calculate the residual\n",
    "model_multi = blend_multi.get_model()\n",
    "\n",
    "model_lr = multi_hsc.render(model_multi)\n",
    "init_rgb = scarlet.display.img_to_rgb(model_multi[:-1], norm=hsc_norm)\n",
    "init_rgb_lr = scarlet.display.img_to_rgb(model_lr, norm=hsc_norm)\n",
    "residual_lr = data_hsc - model_lr\n",
    "# Trim the bottom source not part of the blend from the image\n",
    "residual_lr_rgb = scarlet.display.img_to_rgb(residual_lr[:,:-5])\n",
    "\n",
    "# Get the HR residual\n",
    "residual_hr = (data_hst - multi_hst.render(model_multi))[0]\n",
    "vmax = np.abs(residual_hr).max()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.suptitle('Multi-resolution initialisation', fontsize=36)\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"HSC data\")\n",
    "plt.subplot(235)\n",
    "plt.imshow(init_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"HighRes Model\")\n",
    "plt.subplot(232)\n",
    "plt.imshow(init_rgb_lr)\n",
    "plt.axis('off')\n",
    "plt.title(\"LowRes Model\")\n",
    "plt.subplot(236)\n",
    "plt.imshow(residual_hr, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.axis('off')\n",
    "plt.colorbar(fraction=.045)\n",
    "plt.title(\"HST residual\")\n",
    "plt.subplot(233)\n",
    "plt.imshow(residual_lr_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"HSC residual\")\n",
    "plt.subplot(234)\n",
    "plt.imshow(hst_img[:,:,0])\n",
    "plt.axis('off')\n",
    "plt.colorbar(fraction=.045)\n",
    "plt.title('HST data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_hst.fit(100, e_rel = 1.e-7)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend_hst.loss), -blend_hst.loss[-1]))\n",
    "plt.plot(-np.array(blend_hst.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_hsc.fit(100, e_rel = 1.e-7)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend_hsc.loss), -blend_hsc.loss[-1]))\n",
    "plt.plot(-np.array(blend_hsc.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_multihst.fit(100, e_rel = 1.e-7)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend_multihst.loss), -blend_multihst.loss[-1]))\n",
    "plt.plot(-np.array(blend_multihst.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_multihsc.fit(100, e_rel = 1.e-7)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend_multihsc.loss), -blend_multihsc.loss[-1]))\n",
    "plt.plot(-np.array(blend_multihsc.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time blend_multi.fit(150, e_rel = 1.e-7)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend_multi.loss), -blend_multi.loss[-1]))\n",
    "plt.plot(-np.array(blend_multi.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Full Model\n",
    "First we load the model for the entire blend and its residual. Then we display the model using the same $sinh^{-1}$ stretch as the full image and a linear stretch for the residual to see the improvement from our initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_init(blend_hsc, obs_hsc, data_hsc, 0, img_rgb, 'HSC')\n",
    "display_init(blend_hst, obs_hst, data_hst, 1, data_hst[0], 'HST')\n",
    "display_init(blend_multihsc, obs_hsc, data_hsc, 2, img_rgb, 'multi HSC')\n",
    "display_init(blend_multihst, obs_hst, data_hst, 3, data_hst[0], 'multi HST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi = blend_multi.get_model()\n",
    "model_hr = multi_hst.render(model_multi)\n",
    "model_lr = multi_hsc.render(model_multi)\n",
    "\n",
    "rgb = scarlet.display.img_to_rgb(model_multi[:-1], norm=hsc_norm)\n",
    "rgb_lr = scarlet.display.img_to_rgb(model_lr, norm=hsc_norm)\n",
    "residual_lr = data_hsc - model_lr\n",
    "\n",
    "# Trim the bottom source not part of the blend from the image\n",
    "residual_lr_rgb = scarlet.display.img_to_rgb(residual_lr[:,:])\n",
    "\n",
    "# Get the HR residual\n",
    "residual_hr = (data_hst - model_hr)[0]\n",
    "vmax = residual_hr.max()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(231)\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"HSC data\")\n",
    "plt.subplot(235)\n",
    "plt.imshow(rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"HST Model\")\n",
    "plt.subplot(232)\n",
    "plt.imshow(rgb_lr)\n",
    "plt.axis('off')\n",
    "plt.title(\"HSC Model\")\n",
    "plt.subplot(236)\n",
    "plt.imshow(residual_hr, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.axis('off')\n",
    "plt.colorbar(fraction=.045)\n",
    "plt.title(\"HST residual\")\n",
    "plt.subplot(233)\n",
    "plt.imshow(residual_lr_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"HSC residual\")\n",
    "plt.subplot(234)\n",
    "plt.imshow(hst_img)\n",
    "plt.axis('off')\n",
    "plt.title('HST data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Source Models\n",
    "It can also be useful to view the model for each source. For each source we extract the portion of the image contained in the sources bounding box, the true simulated source flux, and the model of the source, scaled so that all of the images have roughly the same pixel scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "has_truth = False\n",
    "axes = 2\n",
    "\n",
    "for k,src in enumerate(blend_multi.sources):\n",
    "    print('source number ', k)\n",
    "    # Get the model for a single source\n",
    "    source_multi = src.get_model()\n",
    "    source_multihsc = blend_multihsc[k].get_model()\n",
    "    source_multihst = blend_multihst[k].get_model()\n",
    "    \n",
    "    # Display the low resolution image and residuals\n",
    "    img_lr_rgb = scarlet.display.img_to_rgb(model_lr, norm = hsc_norm)\n",
    "    \n",
    "    plt.figure(figsize=(60,12))\n",
    "    \n",
    "    plt.subplot(141)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.plot(Xm[k],Ym[k], 'o', markersize = 10)\n",
    "    plt.title(\"HSC Data\", fontsize = 30)\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(source_multi[0])\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Multi resolution model\", fontsize = 30)\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(source_multihsc[0])\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"HSC Model\", fontsize = 30)\n",
    "    plt.subplot(144)\n",
    "    plt.imshow(source_multihst[-1])\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"HST Model\", fontsize = 30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results:\n",
    "model_multi = blend_multi.get_model()\n",
    "render_hrm = multi_hst.render(model_multi)\n",
    "render_lrm = multi_hsc.render(model_multi)\n",
    "\n",
    "model_hsc = blend_hsc.get_model()\n",
    "render_hsc = obs_hsc.render(model_hsc)\n",
    "\n",
    "model_hst = blend_hst.get_model()\n",
    "render_hst = obs_hst.render(model_hst)\n",
    "\n",
    "model_hscmulti = blend_multihsc.get_model()\n",
    "render_hscmulti = obs_hsc.render(model_hscmulti)\n",
    "\n",
    "model_hstmulti = blend_multihst.get_model()\n",
    "render_hstmulti = obs_hst.render(model_hstmulti)\n",
    "\n",
    "# RGB images of the residuals\n",
    "plt.figure(figsize = (35,10))\n",
    "plt.subplot(131)\n",
    "plt.imshow((data_hsc - render_lrm)[2])\n",
    "plt.colorbar()\n",
    "plt.subplot(132)\n",
    "plt.imshow((data_hsc - render_hscmulti)[2])\n",
    "plt.colorbar()\n",
    "plt.subplot(133)\n",
    "plt.imshow((data_hsc - render_hsc)[2])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# RGB images of the residuals\n",
    "plt.figure(figsize = (35,10))\n",
    "plt.subplot(131)\n",
    "plt.imshow((data_hst - render_hrm)[0])\n",
    "plt.colorbar()\n",
    "plt.subplot(132)\n",
    "plt.imshow((data_hst - render_hstmulti)[0])\n",
    "plt.colorbar()\n",
    "plt.subplot(133)\n",
    "plt.imshow((data_hst - render_hst)[0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSC residuals\n",
    "chi_joint = (np.sum((data_hsc - render_lrm)**2, axis = (-2,-1))/mad_wavelet(data_hsc)**2)**0.5\n",
    "chi_multi = (np.sum((data_hsc - render_hscmulti)**2, axis = (-2,-1))/mad_wavelet(data_hsc)**2)**0.5\n",
    "chi_alone = (np.sum((data_hsc - render_hsc)**2, axis = (-2,-1))/mad_wavelet(data_hsc)**2)**0.5\n",
    "\n",
    "chi_hr = np.sum((data_hst - render_hrm)[0]**2/mad_wavelet(data_hst)**2)**0.5\n",
    "chi_hstmulti = np.sum((data_hst - render_hstmulti)**2/mad_wavelet(data_hst)**2)**0.5\n",
    "chi_hst = np.sum((data_hst - render_hst)**2/mad_wavelet(data_hst)**2)**0.5\n",
    "\n",
    "plt.plot(['g','r','i','z','y'], chi_joint, 'or', label = 'joint')\n",
    "plt.plot(['g','r','i','z','y'], chi_multi, 'ob', label = 'multi detect')\n",
    "plt.plot(['g','r','i','z','y'], chi_alone, 'og', label = 'hsc')\n",
    "plt.yscale('symlog')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# HST residuals\n",
    "plt.plot(['f814w'], chi_hr, 'or', label = 'joint')\n",
    "plt.plot(['f814w'], chi_hstmulti, 'ob', label = 'multi detect')\n",
    "plt.plot(['f814w'], chi_hst, 'og', label = 'hst')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
